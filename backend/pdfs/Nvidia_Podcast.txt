 Hello and welcome to the Nvidia AI podcast from GTC 2025 in San Jose, California. I'm Noah Kravitz and I'm here with Mungal Shah, co-founder and CEO of Hypocratic AI, a startup building a safety focused LLM large language model for healthcare. Hypocratic recently launched a healthcare AI agent app store and announced their series be funding round and is at the forefront of the AI power to healthcare transformation that's happening all around us. I'm excited to talk about AI and the big idea behind the Hypocratic AI, the era of healthcare abundance with Mungal. So welcome and thanks so much for taking the time to join the AI podcast. Oh, I'm so excited to be here. Thank you for having me. So let's start with the basics. What is Hypocratic AI? Well, as you mentioned, we're a safety focused, large language model focused on healthcare and we really used it to build AI clinicians. So we have agents that operate and reach out the patients and call them on the phone and say check in on them post surgery and let's look at your incision site and is it getting infected and do you have enough of your medications and do you need refill? So it's really an agent that talks to patients and delivers care. So when was the company founded? We started about two years ago. And you're in production now with agents interacting with patients? Yeah, we've done as of the end of this month, we will have done about 1.85 million calls into patients all over the country. What's the reaction been like from the patients to getting healthcare from an AI agent? You know, people always ask that question. They're always like, well, what are the patients? The average, I'll give it to you in numbers and I'll give it to you in anecdotes. The average patient rating is an 8.95 out of 10. That's pretty good. Yeah. And second, I think there's about 30% who are like, I don't want to talk to AI. With a little bit of a rebuttal, the AI goes, look, I can really help you. And I don't know when that human's going to call you back because they don't call you back a lot of times. Right. Well, you talk to me, it turns out to about 15%. We'll ultimately leave. But the other 85% will talk to it. And within like 30 seconds, 60 seconds, when they realize this is not your grandfather's IVR, like this truly can understand you and talk to you in an empathetic. They just talk away. People just talk. Yeah. I mean, and think about it in this day and age, like who really listens to every word you say? Like no one ever. And I think that now what you realize is this thing listens to every word and responds and pays attention and gives you its undivided attention. And that's gold in the modern age. Right. Well, for what it's worth, I'm going to go on an limb and say, the listeners are hanging on your every word right now. So I want to ask you about this idea of the age of healthcare abundance. Yeah. That's a North Star. Absolutely. Okay. And what does it mean? I think that when we think about solving our healthcare problems, all of healthcare is premised on this idea of clinical scarcity. The word triage assumes you don't have enough. Right. We got to decide who to take first. Right. Population health uses this word called a risk stratification. We got to help those most in need. What about those almost most in need? Like that'll be in that need next year. Right. The condition keeps deteriorating. Oh, we can't help them because we have limited resources. And so I think we've always been thinking about healthcare as saying, you know, we don't have enough. How do we spread it around instead of how do we get to a place where it's infinitely abundance? And now, you know, we do. We have these AI agents. We have an infinite supply of them. They speak every language. They remember every conversation. They're clinically safe and they can take care of everybody at all times. And I think clinical abundance is the way to solve a lot of the world's problems in healthcare. You know, imagine if everybody has a caregiver, a clinic, you know, a care manager calling them up and seeing how they're doing and checking their blood pressure every single day. And I think we're beginning to enter that. And then there's some other implications of it. You know, today, when there's a heat wave, we don't call every patient at risk at the hottest two hours of the day and do a heat stroke assessment. And if they're having issues, send them an Uber to get them to a cooling center, you couldn't do that with that AI. Like, you can't get enough humans together to do that every single day of a heat wave with only like five days notice, right? Right. Right. But now you can. This may not be the right phrase to use, but I keep thinking of the phrase last mile of delivery. What happens when the patient needs to be seen by a human or needs some kind of physical interaction beyond the phone call? Yeah, you know, where we can operate today with technology is in this virtual care area. But this is where we have our human clinicians, right? Like everybody's like, well, you know, how does this relate to the human clinicians? I'm like, we need the human clinicians to do all of the physical care that needs to be done. And in fact, by focusing the AI on these areas, we'll free them up to do even more of that. And so I think that given the technology we have today, I think that we can do the virtual part, but we'll leave the humans to do the physical part. Right. So hypocritic just launched hypocritic AI's healthcare AI agent app store. Yeah. Okay. How does that work? So one of the things we realized was this is one of the powers of kind of general intelligence and specific intelligence. Once you've built an LLM for healthcare, you know, then making a new use case takes four minutes, right? You just write a different prompt. Right. We're so used to software that's a specific intelligence that it takes you three to six months to make a new use case that people don't realize like you can just make them quickly. I mean, nobody goes to chat to you, Pt and says, what use cases do you support? Right. Yeah. People ask us that question all the time. And really the realization is, well, I support probably everyone you think of, just try writing it. See what happens. So then we realized, oh, we can write these in four minutes. Okay. We could write a ton of them, but we don't have all the knowledge to write them. Why don't we recruit every clinician in the country to come be an author? You know, if you worked in a concussion clinic as a nurse for the last 20 years, and you know all kinds of little details of what to ask in a way that maybe isn't standard protocol, but is an enhancement to it. Right. Yeah. Yeah. Why don't you ask these questions and write a new script and then put your script in our app store. We'll validate it. We'll run it through safety testing. And then once it's live, you'll get paid a portion of all the revenue it makes. Some like leverage your intellectual property and expertise and experience over the years and get paid while you sleep. And so it's, and from our standpoint, we're now crowdsourcing, but only from clinicians. You actually have to send us your license member. We validate that you're a licensed US clinician. And then we really say, hey, your use case can help millions of patients all over the country, not just the ones you personally can treat, giving you a scale of impact that you never had in your career before. So I want to ask you about inference, all to talk about generative AI, LLM's past couple of years, a lot to talk about training, the cost of training, the energy of training, the dating for training. Now we're all talking about inference, yeah, Hippocratic AI's been talking about inference. What is inference driven AI healthcare? I mean, in our case, you know, we trained our model differently than others. And we've always been focused on inference because our runtime is the key environment. Our model is actually 22 models. It's not one model. It's one gigantic 400 B model doing the talking. And it's 19 supervising it and making sure it doesn't say anything unsafe within this scope, this non diagnostic clinical scope. So we're not, you know, we're not a doctor, we're not diagnosing, we're not prescribing. And then there's another two deep thinking models that take 30 seconds to a minute to double check everybody on top of all that. Right, right. Well, that's a lot of inference. That's 22 models of inference. It's 4.2 trillion parameters. We're running every time every time. And so we use a button. In fact, our entire instance today takes up over 128 NVIDIA H100 GPUs just to load in a ram. Wow. Before, you know, and now that can support many simultaneous conversations. But yeah, even spin up one agent takes a ton because we use so much RAM. Right. But this is all our focuses is this inference, this inference stack. I think people haven't thought about inference. Yeah. They haven't built the infrastructure for it. In fact, this is some of the conversation I'm having with a lot of people, including the NVIDIA team, but also some of the hyperscalers out there and just saying, Hey, guys, you know, I don't want to buy your servers for 24 hours, seven days a week, 365, because I can only call patients during these hours. Right. So I'd like on demand GPUs. Oh, I'll give you on demand GPUs. But I'll give you at five times the price. I'm like, that doesn't really help me. I need them for about six hours a day. So anything over four, I'm better off having bought them all the time. But what I really need is you to sell me a modern demand. And so people are starting to come up with that technology. They're starting to come up with how do you spin up loading that much into RAM takes forever. So right now, the time to spin up a new, like if say this, this one instance gets saturated, we get too many inbound calls from patients at the same time. It takes like 20 to 30 minutes to spin up another instance. Yeah. Well, the whole point of an AI agent is that you don't wait on hold. Abundance. Abundance. Abundance 30 minutes from now. And so, and even many of the hyperskillers, you have to email somebody to get more servers allocated to you. Like, it's not a fully dynamic thing. The way it is on the non GPU side. And so there's a lot of new infrastructure needed to really make this happen. I think the third part of this is actually something we've been uniquely working with in video on. We have a different technology problem than a lot of the other players in the LM space. Most of them are doing text oriented search stuff and text interactions. Right. Well, they're going another few more seconds in giving you a response. Like, you know, deep seek takes, you know, the R1 of DC takes longer to give you an answer but it gives you a deeper answer, right? 30 seconds, 20 seconds in a text search. There's no big deal if you give me the perfect essay. So I don't have to do my homework. Sure. Right. But in a voice conversation and all those vars or voice, you have about 1.5 to 2 second budget and to end. And so we're really focused on latency. And so our inference isn't a matter of trying to optimize cost-pertokin but trying to optimize latency. And that's a very different kind of focus. And we do that everywhere. Like we're working with Nvidia on what to do on the chip level as well as the kind of additional infrastructure that Nvidia provides. We're also looking to do that on the inference engines that we're using. We actually had to take an open source and tune it a different way because all the other ones are being tuned for throughput or cost-pertokin, not for latency. And so we basically worked on lots of different elements to really get the speed we need out of this. So what's the constellation architecture? Yes. So that's the thing I was describing. We literally have multiple models double checking each other. Right. So what we're going to do is we're going to do a lot of the models now. They say you can give a lot of input tokens to them now. Just put it all in there. It'll figure it out. And you want to jemenize like what a million I think it is now. Millions tokens. So it's like, oh, okay. Yeah. No problem. Right. But he can't reason across it all. Yeah. They'll show you examples of what we're called needle in haystacks where it'll be like, okay, we'll find that one thing. Mm-hmm. Yeah, I mean, grapping for a word is not that hard for computer science. Like we can find a word. But what you're really trying to do is reason across it. So I'll give an example. If you ask your care manager, can I have ibuprofen? And they say, sure, you can have ibuprofen, but don't take too much. That's fine, right? Because it's an over the countermedication. Unless you have chronic kidney disease stage three or four, then it'll kill you. Right. Well, if you put the rules for ibuprofen and CKD into GPT-4 and then ask it, it'll do great. If you put in all the rules for all conditions specific over the countermedications and ask, it'll still do pretty good. Because we'll start missing some sometimes, which is still okay, because you could kill people. Right. Fine. Have you put in the patient's medical history, the patient's last 10 conversations with you, all of those rules for over the countermedication disallowance and the current checklist for what you're supposed to follow with that patient and maybe a few other things and then ask it. Yep. Good luck. And what it is is we have an attention span problem. But if you have multiple models, we have these other models only focused on checking one thing at a time. So there's an overdose attention and it listens to every turn of the conversation. It's like, are we talking about drugs? Are we talking about drugs? Yes, we're talking about drugs. Okay. Right. And then it's like, well, okay, did somebody just say a number that's an overdose relative to their prescription or relative to max toxicity of what you can have of that drug? Okay, did. And it may not seem that hard for pills versus two pills, but when you're talking about creams and injectables, it gets quite hard. Sure. And then you're like testosterone cream and I rubbed it on my hand. Was that an overdose? Right. I don't know. How much cream was in your hand? Right. What's a little bit? What's a little bit? Was it a pea size? Was it a cherry tomato size? Was it an apple size? Right. RLM knows how to ask all these questions and knows how to navigate assessing whether it's actually an overdose. And you cannot have, if a patient shares an overdose information with a care manager in a clinical setting, you need to do something. Yeah. You may have said this at the beginning, so forgive me. How many clinicians, doctors and how many patients are you working with right now? Couple different things. So first is to test and certify the product. We basically ran a quasi like output testing trial. So a lot of people say, hey, tell me what you trained your LLM on. So I know it's safe. I don't know who came up with this question because you have things like PubMed GPT that's trained only on PubMed, a evidence-based archive. And it still gives you stuff that's not right. So I mean, or it'll conflate two things and give you things, not right. So what we realized was you got to do output testing. You got to test every output, but you can't test every output of a horizontal model. What? There's an infinite number of permutation combinations of GPT-4. But you can. It turns out, do that for a vertical model when you roll it out one use case at a time. Right. I'm doing a pre-op call for a colonoscopy. I'm going to make sure you took your bowel prep. I'm going to make sure you've fasted the night before. I'm going to do all the steps. Okay, we hire a ton of clinicians to act like patients, call it up when we first make the news use case, and mark every error. And then we go back and keep improving the thing until we've done that. So we've now done that six thousand, we have six thousand US licensed clinicians who have now done 309,000 clinical test calls. And so we call this output testing. We've done more output testing than anybody. Yeah. You know, we spent, you know, double digit millions of dollars basically certifying the safety of the product. So we got it up by looking at its architecture or how it was trained, but looking at what it finally does in the end. Yep, yep. And if this is going to call my mother, you know, she's 81 years old, like I want to know what it's going to say in the end. I'm not comforted by, oh, I trained it on this. Right, right. Yep. So it's still told my mom to take 10 adverts on it. Yeah, right. Like that's not okay. So I think these are the benefits of really having a large clinically driven thing. And I mean, who knows best how to assess an AI except the clinicians? We've been speaking about this a little bit, but what if some of the other or some of the biggest challenges been in developing this inference, inference based system? The analogy I draw at the company is like, this space is evolving so fast. We're crossing a wood plank bridge and the planks are showing up like two seconds and three seconds to step. And when we first started the company, there was no open source and all the sudden open source arrived. Right. There was no optimized inference engines and then all of a sudden those arrived. There was not a really good TTS and all of a sudden a great TTS that text the speech engine arrived. And so one of the things has been we've had to redo some work. Sure. Right. Because we did it. And then those things showed up and realized there was a better way to do it. So you got to redo the work. And so I think one of the challenges has just been keeping up with kind of how things are evolving. Yep. I think the other one has just been running counter to a lot of people's kind of core thesis. Because they're all going after this cost-protoking. Our infrastructure needs are different. But we also have a different budget. It's made it a little easier. Because we're offsetting a very expensive resource per hour. Right. And so that's been that. Right. I mean, the other stuff is all normal go-to-market stuff. Yep. New technology. People want to know more about it. How do you know it's safe? That sort of thing. I asked you about it and you said this is the first question people ask about, you know, how are the patients reacting? What about on the clinician side? Are doctors, other caregivers excited to work with you? They worry about this kind of taking their role. What's the vibe like? I think there's such a shortage there. Yeah. And post-apandemic, they really had. Yeah. Yeah, they realized like we got to do something else. Right. Right. I mean, if you try to get a PCP here in Santa Clara County, it's like six months. Right. I mean, you want to see a specialist. It's pretty bad. In fact, the other day, somebody was telling me they're like, oh, conflite in New York and get your test done. Because you know, you will get it done in a month. Like, I'm like, really? Like that's our answer. Right. And so, I think we have no choice. And so, and most of the, most people realize that and they realize there's an opportunity. And then when you start talking about this idea of abundance, they realize there's a whole bunch of things you can do that you never could do before. And I think that we've seen it open arms. We signed up 25 health systems providers and pharmaclients in basically six, seven months. Since we took the product GA about last June, and in healthcare, you never get that. And we have another, we actually will sign another three this month. By the end of by the next June, I bet you will be at like 30 to 40. That's a number that normally you're a health tech startup at like year seven or year five. Right. Like you're way down the line. The needs there. There, there's a lot of pain around stuffy and staffing shortages. Right. What's next for Hippocratic? What's the rest of the year, the next couple years, whatever the timeframe is, what can you tell us about the future roadmap? You know, we're continuing to expand. I mean, so I think there's a couple of directions. So one is we're really pushing hard into the payers base and providing them. A lot of payers have large teams of what are called case managers that reach out to patients and follow up and make sure they're doing their proper treatment protocol because otherwise it ends up more expense for the payers. And by payer, I mean health insurance companies. We're doing the same for pharma. You know, they're running all these clinical trials and they're like, look, the AI can just call and make sure every day at 4 p.m. when you're supposed to take that med, you take that med because if you don't, you mess up the trial. There's also some interesting ways to use the technology for clinical trial recruitment or kind of even qualification. You could ask every patient, you know, there's a lot of soft factors in clinical trial qualification. Sure. And it's like, oh, you know, do you get a rash when you put the continuous glucose meter sensors on because we don't want you in the trial if you do because to diabetes trial, then you're going to take it off and it's not going to work. That's not in your health record that you get a rash, like very unlikely. And so, you know, but I could call up a whole bunch of people and ask and kind of figure it out. So I think there's some really interesting ideas like that. We're also expanding internationally. We just did our first deal in UAE. For sure. We're about to do another set of deals in Southeast Asia. Great. We're seeing the whole. I actually thought it was mostly just the US short of clinical staff, maybe a little Europe. I really were. We're all this short. And you know, with the aging population and so much of the planet, you know, basically we all have no choice. And so we're seeing quite a large demand all over. When job for listeners who'd like to know more about the company, about any of the aspects that we're talking about, the website, the best place to go. Yeah. Hi, Picraticai.com. We have a lot about our LLM and the architecture. We published a paper on that. We recently also put out a paper on our safety testing protocol. Oh, great. We actually hope it becomes a kind of a way that everybody starts testing kind of mission critical LLM stuff. Yeah. And basically this output testing and how we did it in detail, how we hired the people, how we tested the cohorts, how we compared them the human clinicians. And you know, we hope that that sets a new framework for how to do that. And then you can also just read about the company and our our history and kind of what we've done and our values and things like that. Fantastic. Well, when job, thank you for taking the time. It's going to say to tell us about Hi Picratic, but you've been, it's a short time, but, you know, the name is out there. People know so it's great to get an update and the work you're doing and the approach to safety and checking the output testing and these really fascinating. So appreciate taking the time to come tell us about it. Thank you for having me.